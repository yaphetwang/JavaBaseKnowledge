1. 异常
Exception和Error都是继承了Throwable类，
在Java中只有Throwable类型的实例才可以被抛出（throw）或者捕获（catch），
它是异常处理机制的基本组成类型。
Exception和Error体现了Java平台设计者对不同异常情况的分类。
Exception是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。
Error是指在正常情况下，不大可能出现的情况，绝大部分的Error都会导致程序（比如JVM自身）处于非正常的、不可恢复状态。
既然是非正常情况，所以不便于也不需要捕获，常见的比如OutOfMemoryError之类，都是Error的子类。

Exception又分为可检查（checked）异常和不检查（unchecked）异常，
可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。
前面我介绍的不可查的Error，是Throwable不是Exception。
不检查异常就是所谓的运行时异常，类似 NullPointerException、ArrayIndexOutOfBoundsException之类，
通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。


Throw early, catch late原则

Checked Exception不兼容functional编程，如果你写过Lambda/Stream代码，相信深有体会

我们从性能角度来审视一下Java的异常处理机制，这里有两个可能会相对昂贵的地方：
try-catch代码段会产生额外的性能开销，或者换个角度说，它往往会影响JVM对代码进行优化，
     所以建议仅捕获有必要的代码段，尽量不要一个大的try包住整段的代码；
     与此同时，利用异常控制代码流程，也不是一个好主意，
     远比我们通常意义上的条件语句（if/else、switch）要低效。
Java每实例化一个Exception，都会对当时的栈进行快照，这是一个相对比较重的操作。
     如果发生的非常频繁，这个开销可就不能被忽略了。

当我们的服务出现反应变慢、吞吐量下降的时候，检查发生最频繁的Exception也是一种思路



2. final，finally，finalize有什么不同？
final可以用来修饰类、方法、变量，分别有不同的意义，final修饰的class代表不可以继承扩展，
final的变量是不可以修改的，而final的方法也是不可以重写的（override）。
final字段对性能的影响，大部分情况下，并没有考虑的必要

finally则是Java保证重点代码一定要被执行的一种机制。
我们可以使用try-finally或者try-catch-finally来进行类似关闭JDBC连接、保证unlock锁等动作。

finalize是基础类java.lang.Object的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize机制现在已经不推荐使用，并且在JDK 9开始被标记为deprecated。

注意，final不是immutable！
final List<String> strList = new ArrayList<>(); 
strList.add("Hello"); 
strList.add("world"); 
List<String> unmodifiableStrList = List.of("hello", "world"); 
unmodifiableStrList.add("again");
final只能约束strList这个引用不可以被赋值，但是strList对象行为不被final影响，添加元素等操作是完全正常的。如果我们真的希望对象本身是不可变的，那么需要相应的类支持不可变的行为。
在上面这个例子中，List.of 方法创建的本身就是不可变List，最后那句add是会在运行时抛出异常的



3. 强引用、软引用、弱引用、幻象引用
在Java语言中，除了原始数据类型的变量，其他所有都是所谓的引用类型，指向各种不同的对象，
理解引用对于掌握Java对象生命周期和JVM内部相关机制非常有帮助

不同的引用类型，主要体现的是对象不同的可达性（reachable）状态和对垃圾收集的影响

所谓强引用（“Strong” Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，
就能表明对象还“活着”，垃圾收集器不会碰这种对象。
对于一个普通的对象，如果没有其他的引用关系，
只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以被垃圾收集的了，
当然具体回收时机还是要看垃圾收集策略。

软引用（SoftReference），是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当JVM认为内存不足时，才会去试图回收软引用指向的对象。
JVM会确保在抛出OutOfMemoryError之前，清理软引用指向的对象。
软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，
当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。

弱引用（WeakReference）并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。
这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，
如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择，如ThreadLocal就使用了

对于幻象引用，有时候也翻译成虚引用，你不能通过它访问对象。
幻象引用仅仅是提供了一种确保对象被finalize以后，做某些事情的机制，
比如，通常用来做所谓的Post-Mortem清理机制，
我在专栏上一讲中介绍的Java平台自身Cleaner机制等，也有人利用幻象引用监控对象的创建和销毁。


4. String、StringBuffer、StringBuilder
String是Java语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。
它是典型的Immutable类，被声明成为final class，所有属性也都是final的。
也由于它的不可变性，类似拼接、裁剪字符串等动作，都会产生新的String对象。
由于字符串操作的普遍性，所以相关操作的效率往往对应用性能有明显影响。
StringBuffer是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，
我们可以用append或者add方法，把字符串添加到已有序列的末尾或者指定位置。
StringBuffer本质是一个线程安全的可修改字符序列，
它保证了线程安全，也随之带来了额外的性能开销，
所以除非有线程安全的需要，不然还是推荐使用它的后继者，也就是StringBuilder。
StringBuilder是Java 1.5中新增的，在能力上和StringBuffer没有本质区别，
但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。



5. 反射，动态代理
反射机制是Java语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。
通过反射我们可以直接操作类或者对象，
比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义
动态代理是一种方便运行时动态构建代理、动态处理代理方法调用的机制，
很多场景都是利用类似机制做到的，比如用来包装RPC调用、面向切面的编程（AOP）
实现动态代理的方式很多，比如JDK自身提供的动态代理，就是主要利用了上面提到的反射机制
还有其他的实现方式，
比如利用传说中更高性能的字节码操作机制，类似ASM、cglib（基于ASM）、Javassist等

反射提供的AccessibleObject.setAccessible(boolean flag)。
它的子类也大都重写了这个方法，这里的所谓accessible可以理解成修饰成员的public、protected、private，
这意味着我们可以在运行时修改成员访问限制！
setAccessible的应用场景非常普遍，遍布我们的日常开发、测试、依赖注入等各种框架中。
比如，在O/R Mapping框架中，我们为一个Java实体对象，运行时自动生成setter、getter的逻辑，
这是加载或者持久化数据非常必要的，框架通常可以利用反射做这个事情，
而不需要开发者手动写类似的重复代码。比如lombok的注解

JDK Proxy的优势：
最小化依赖关系，减少依赖意味着简化开发和维护，JDK本身的支持，可能比cglib更加可靠。
平滑进行JDK版本升级，而字节码类库通常需要进行更新以保证在新版Java上能够使用。
代码实现简单。
基于类似cglib框架的优势：
有的时候调用目标可能不便实现额外接口，从某种角度看，限定调用者实现接口是有些侵入性的实践，类似cglib动态代理就没有这种限制。
只操作我们关心的类，而不必为其他相关类增加工作量。
高性能。



6. 基本类型和包装类
int是我们常说的整形数字，
是Java的8个原始数据类型
（Primitive Types，boolean、byte 、short、char、int、float、double、long）之一。
Java语言虽然号称一切都是对象，但原始数据类型是例外。
Integer是int对应的包装类，它有一个int类型的字段存储数据，并且提供了基本操作，
比如数学运算、int和字符串之间转换等。
在Java 5中，引入了自动装箱和自动拆箱功能（boxing/unboxing），
Java可以根据上下文，自动进行转换，极大地简化了相关编程。
关于Integer的值缓存，这涉及Java 5中另一个改进。
构建Integer对象的传统方式是直接调用构造器，直接new一个对象。
但是根据实践，我们发现大部分数据操作都是集中在有限的、较小的数值范围，
因而，在Java 5中新增了静态工厂方法valueOf，在调用它的时候会利用一个缓存机制，带来了明显的性能改进。
按照Javadoc，这个值默认缓存是-128到127之间。




7. Vector、ArrayList、LinkedList
这三者都是实现集合框架中的List，也就是所谓的有序集合，
因此具体功能也比较近似，比如都提供按照位置进行定位、添加或者删除的操作，都提供迭代器以遍历其内容等。
但因为具体的设计区别，在行为、性能、线程安全等方面，表现又有很大不同。
Vector是Java早期提供的线程安全的动态数组，如果不需要线程安全，并不建议选择，毕竟同步是有额外开销的。Vector内部是使用对象数组来保存数据，可以根据需要自动的增加容量，
当数组已满时，会创建新的数组，并拷贝原有数组数据。
ArrayList是应用更加广泛的动态数组实现，它本身不是线程安全的，所以性能要好很多。
与Vector近似，ArrayList也是可以根据需要调整容量，
不过两者的调整逻辑有所区别，Vector在扩容时会提高1倍，而ArrayList则是增加50%。
LinkedList顾名思义是Java提供的双向链表，所以它不需要像上面两种那样调整容量，它也不是线程安全的。


另外一个经常会被考察到的问题，就是理解Java提供的默认排序算法，具体是什么排序方式以及设计思路等。
这个问题本身就是有点陷阱的意味，
因为需要区分是Arrays.sort()还是Collections.sort() （底层是调用Arrays.sort()）；什么数据类型；
多大的数据集（太小的数据集，复杂排序是没必要的，Java会直接进行二分插入排序）等。
对于原始数据类型，目前使用的是所谓双轴快速排序（Dual-Pivot QuickSort），是一种改进的快速排序算法，早期版本是相对传统的快速排序，你可以阅读源码。
而对于对象数据类型，目前则是使用TimSort，
     思想上也是一种归并和二分插入排序（binarySort）结合的优化排序算法。
     TimSort并不是Java的独创，简单说它的思路是查找数据集中已经排好序的分区（这里叫run），
     然后合并这些分区来达到排序的目的。
另外，Java 8引入了并行排序算法（直接使用parallelSort方法），
这是为了充分利用现代多核处理器的计算能力，底层实现基于fork-join框架，
当处理的数据集比较小的时候，差距不明显，甚至还表现差一点；
但是，当数据集增长到数万或百万以上时，提高就非常大了，具体还是取决于处理器和系统环境




8. 对比Hashtable、HashMap、TreeMap有什么不同
HashTable、HashMap、TreeMap都是最常见的一些Map实现，
是以键值对的形式存储和操作数据的容器类型。
HashTable是早期Java类库提供的一个哈希表实现，本身是同步的，不支持null键和值，
由于同步导致的性能开销，所以已经很少被推荐使用。
HashMap是应用更加广泛的哈希表实现，行为上大致上与HashTable一致，
主要区别在于HashMap不是同步的，支持null键和值等。
通常情况下，HashMap进行put或者get操作，可以达到常数时间的性能，
所以它是绝大部分利用键值对存取场景的首选，比如，实现一个用户ID和用户信息对应的运行时存储结构
TreeMap则是基于红黑树的一种提供顺序访问的Map，和HashMap不同，
它的get、put、remove之类操作都是O（log(n)）的时间复杂度，
具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断

为什么HashMap要树化呢？
本质上这是个安全问题。
因为在元素放置过程中，如果一个对象哈希冲突，都被放置到同一个桶里，则会形成一个链表，
我们知道链表查询是线性的，会严重影响存取的性能
而在现实世界，构造哈希冲突的数据并不是非常复杂的事情，
恶意代码就可以利用这些数据大量与服务器端交互，导致服务器端CPU大量占用，
这就构成了哈希碰撞拒绝服务攻击，国内一线互联网公司就发生过类似攻击事件



9. 如何保证集合是线程安全的? ConcurrentHashMap如何实现高效地线程安全？
Java提供了不同层面的线程安全支持。
在传统集合框架内部，除了HashTable等同步容器，
还提供了所谓的同步包装器（Synchronized Wrapper），
我们可以调用Collections工具类提供的包装方法，来获取一个同步的包装容器
（如Collections.synchronizedMap），但是它们都是利用非常粗粒度的同步方式，
在高并发情况下，性能比较低下。
另外，更加普遍的选择是利用并发包提供的线程安全容器类，它提供了：
各种并发容器，比如ConcurrentHashMap、CopyOnWriteArrayList。
各种线程安全队列（Queue/Deque），如ArrayBlockingQueue、SynchronousQueue。
各种有序容器的线程安全版本等。
具体保证线程安全的方式，包括有从简单的synchronize方式，到基于更加精细化的，
比如基于分离锁（jdk8以前）实现的ConcurrentHashMap等并发实现等。
具体选择要看开发的场景需求，总体来说，并发包内提供的容器通用场景，远优于早期的简单同步实现。




10. java IO
Java IO方式有很多种，基于不同的IO抽象模型和交互方式，可以进行简单区分。
首先，传统的java.io包，它基于流模型实现，提供了我们最熟知的一些IO功能，
比如File抽象、输入输出流等。交互方式是同步、阻塞的方式，
也就是说，在读取输入流或者写入输出流时，在读、写动作完成之前，线程会一直阻塞在那里，
它们之间的调用是可靠的线性顺序。
java.io包的好处是代码比较简单、直观，缺点则是IO效率和扩展性存在局限性，容易成为应用性能的瓶颈。
很多时候，人们也把java.net下面提供的部分网络API，
比如Socket、ServerSocket、HttpURLConnection也归类到同步阻塞IO类库，因为网络通信同样是IO行为

第二，在Java 1.4中引入了NIO框架（java.nio包），提供了Channel、Selector、Buffer等新的抽象，
可以构建多路复用的、同步非阻塞IO程序，同时提供了更接近操作系统底层的高性能数据操作方式。

第三，在Java 7中，NIO有了进一步的改进，也就是NIO 2，引入了异步非阻塞IO方式，
也有很多人叫它AIO（Asynchronous IO）。
异步IO操作基于事件和回调机制，可以简单理解为，应用操作直接返回，而不会阻塞在那里，
当后台处理完成，操作系统会通知相应线程进行后续工作。


如何提高类似拷贝等IO操作的性能，有一些宽泛的原则：
在程序中，使用缓存等机制，合理减少IO次数（在网络通信中，如TCP传输，window大小也可以看作是类似思路）。
使用transferTo等机制，减少上下文切换和额外IO操作。
尽量减少不必要的转换过程，比如编解码；对象序列化和反序列化，比如操作文本文件或者网络通信，如果不是过程中需要使用文本信息，可以考虑不要将二进制信息转换成字符串，直接传输二进制信息。


11. 谈谈你知道的设计模式？
大致按照模式的应用目标分类，设计模式可以分为创建型模式、结构型模式和行为型模式。
创建型模式，是对对象创建过程的各种问题和解决方案的总结，包括各种工厂模式（Factory、Abstract Factory）、单例模式（Singleton）、构建器模式（Builder）、原型模式（ProtoType）。
结构型模式，是针对软件设计结构的总结，关注于类、对象继承、组合方式的实践经验。常见的结构型模式，包括桥接模式（Bridge）、适配器模式（Adapter）、装饰者模式（Decorator）、代理模式（Proxy）、组合模式（Composite）、外观模式（Facade）、享元模式（Flyweight）等。
行为型模式，是从类或对象之间交互、职责划分等角度总结的模式。比较常见的行为型模式有策略模式（Strategy）、解释器模式（Interpreter）、命令模式（Command）、观察者模式（Observer）、迭代器模式（Iterator）、模板方法模式（Template Method）、访问者模式（Visitor）

Spring如何在API设计中使用设计模式。你至少要有个大体的印象，如：
BeanFactory和ApplicationContext应用了工厂模式。
在Bean的创建中，Spring也为不同scope定义的对象，提供了单例和原型等模式实现。
AOP领域则是使用了代理模式、装饰器模式、适配器模式等。
各种事件监听器，是观察者模式的典型应用。
类似JdbcTemplate等则是应用了模板模式。

双检锁单例模式：
这里的volatile能够提供可见性，以及保证getInstance返回的是初始化完全的对象。
在同步之前进行null检查，以尽量避免进入相对昂贵的同步块。
直接在class级别进行同步，保证线程安全的类方法调用。

在这段代码中，争论较多的是volatile修饰静态变量，
当Singleton类本身有多个成员变量时，需要保证初始化过程完成后，才能被get到。
在现代Java中，内存排序模型（JMM）已经非常完善，
通过volatile的write或者read，能保证所谓的happen-before，
也就是避免常被提到的指令重排。换句话说，构造对象的store指令能够被保证一定在volatile read之前。



12. 并发
线程安全需要保证几个基本特性：
原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。
可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，
      通常被解释为将线程本地状态反映到主内存上，volatile就是负责保证可见性的。
有序性，是保证线程内串行语义，避免指令重排等。

如果说ReentrantLock是synchronized的替代选择，
Condition则是将wait、notify、notifyAll等操作转化为相应的对象，
将复杂而晦涩的同步操作转变为直观可控的对象行为。


synchronized底层如何实现？什么是锁的升级、降级？


从操作系统的角度，可以简单认为，线程是系统调度的最小单元，
一个进程可以包含多个线程，作为任务的真正运作者，
有自己的栈（Stack）、寄存器（Register）、本地存储（Thread Local）等，
但是会和进程内其他线程共享文件描述符、虚拟地址空间等。
在具体实现中，线程还分为内核线程、用户线程，
Java的线程实现其实是与虚拟机相关的。对于我们最熟悉的Sun/Oracle JDK，其线程也经历了一个演进过程，
基本上在Java 1.2之后，JDK已经抛弃了所谓的Green Thread，也就是用户调度的线程，
现在的模型是一对一映射到操作系统内核线程。



基本上死锁的发生是因为：
互斥条件，类似Java中Monitor都是独占的，要么是我用，要么是你用。
互斥条件是长期持有的，在使用结束之前，自己不会释放，也不能被其他线程抢占。
循环依赖关系，两个或者多个个体之间出现了锁的链条环。

可能的避免死锁的思路和方法：
第一种方法
如果可能的话，尽量避免使用多个锁，并且只有需要时才持有锁。
否则，即使是非常精通并发编程的工程师，也难免会掉进坑里，
嵌套的synchronized或者lock非常容易出问题。
所以，从程序设计的角度反思，如果我们赋予一段程序太多的职责，
出现“既要…又要…”的情况时，可能就需要我们审视下设计思路或目的是否合理了。
对于类库，因为其基础、共享的定位，比应用开发往往更加令人苦恼，需要仔细斟酌之间的平衡

第二种方法
如果必须使用多个锁，尽量设计好锁的获取顺序。

第三种方法
使用带超时的方法，为程序带来更多可控性。
类似Object.wait(…)或者CountDownLatch.await(…)，都支持所谓的timed_wait，
我们完全可以就不假定该锁一定会获得，指定超时时间，并为无法得到锁时准备退出逻辑。
并发Lock实现，如ReentrantLock还支持非阻塞式的获取锁操作tryLock()，
这是一个插队行为（barging），并不在乎等待的公平性，
如果执行时对象恰好没有被独占，则直接获取锁。
有时，我们希望条件允许就尝试插队，不然就按照现有公平性规则等待，
一般采用下面的方法：
if (lock.tryLock() || lock.tryLock(timeout, unit)) {   	// ...    }


我们通常所说的并发包也就是java.util.concurrent及其子包，集中了Java并发的各种基础工具类，
具体主要包括几个方面：
提供了比synchronized更加高级的各种同步结构，包括CountDownLatch、CyclicBarrier、Semaphore等，可以实现更加丰富的多线程操作，比如利用Semaphore作为资源控制器，限制同时进行工作的线程数量。
各种线程安全的容器，比如最常见的ConcurrentHashMap、有序的ConcurrentSkipListMap，或者通过类似快照机制，实现线程安全的动态数组CopyOnWriteArrayList等。
各种并发队列实现，如各种BlockingQueue实现，比较典型的ArrayBlockingQueue、 SynchronousQueue或针对特定场景的PriorityBlockingQueue等。
强大的Executor框架，可以创建各种不同类型的线程池，调度任务运行等，绝大部分情况下，不再需要自己从头实现线程池和任务调度器。

java.util.concurrent包提供的容器（Queue、List、Set）、Map，
从命名上可以大概区分为Concurrent*、CopyOnWrite和Blocking等三类，
同样是线程安全容器，可以简单认为：
Concurrent类型没有类似CopyOnWrite之类容器相对较重的修改开销。
但是，凡事都是有代价的，Concurrent往往提供了较低的遍历一致性。你可以这样理解所谓的弱一致性，例如，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍历。
与弱一致性对应的，就是我介绍过的同步容器常见的行为“fail-fast”，也就是检测到容器在遍历过程中发生了修改，则抛出ConcurrentModificationException，不再继续遍历。
弱一致性的另外一个体现是，size等操作准确性是有限的，未必是100%准确。
与此同时，读取的性能具有一定的不确定性。



13. JVM
一般来说，我们把Java的类加载过程分为三个主要步骤：加载、链接、初始化，
具体行为在Java虚拟机规范里有非常详细的定义。
首先是加载阶段（Loading），它是Java将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构（Class对象），这里的数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等；如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。
加载阶段是用户参与的阶段，我们可以自定义类加载器，去实现自己的类加载过程。
第二阶段是链接（Linking），这是核心的步骤，简单说是把原始的类定义信息平滑地转化入JVM运行的过程中。这里可进一步细分为三个步骤：
验证（Verification），这是虚拟机安全的重要保障，JVM需要核验字节信息是符合Java虚拟机规范的，否则就被认为是VerifyError，这样就防止了恶意信息或者不合规的信息危害JVM的运行，验证阶段有可能触发更多class的加载。
准备（Preparation），创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。
解析（Resolution），在这一步会将常量池中的符号引用（symbolic reference）替换为直接引用。在Java虚拟机规范中，详细介绍了类、接口、方法和字段等各个方面的解析。
最后是初始化阶段（initialization），这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。
再来谈谈双亲委派模型，简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载Java类型。

除了程序计数器，其他区域都有可能会因为可能的空间不足发生OutOfMemoryError，简单总结如下：
堆内存不足是最常见的OOM原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定JVM堆大小或者指定数值偏小；或者出现JVM处理引用不及时，导致堆积起来，内存无法释放等。
而对于Java虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM实际会抛出StackOverFlowError；当然，如果JVM试图去扩展栈空间的的时候失败，则会抛出OutOfMemoryError。
对于老版本的Oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现OutOfMemoryError也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似Intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError: PermGen space”。
随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了：“java.lang.OutOfMemoryError: Metaspace”。
直接内存不足，也会导致OOM


JVM会把虚拟机栈和本地方法栈中正在引用的对象、静态属性引用的对象和常量，作为GC Roots


jvm基本的调优思路可以总结为：
理解应用需求和问题，确定调优目标。假设，我们开发了一个应用服务，但发现偶尔会出现性能抖动，出现较长的服务停顿。评估用户可接受的响应时间和业务量，将目标简化为，希望GC暂停尽量控制在200ms以内，并且保证一定标准的吞吐量。
掌握JVM和GC的状态，定位具体的问题，确定真的有GC调优的必要。具体有很多方法，比如，通过jstat等工具查看GC等相关状态，可以开启GC日志，或者是利用操作系统提供的诊断工具等。例如，通过追踪GC日志，就可以查找是不是GC在特定时间发生了长时间的暂停，进而导致了应用响应不及时。
这里需要思考，选择的GC类型是否符合我们的应用特征，如果是，具体问题表现在哪里，是Minor GC过长，还是Mixed GC等出现异常停顿情况；如果不是，考虑切换到什么类型，如CMS和G1都是更侧重于低延迟的GC选项。
通过分析确定具体调整的参数或者软硬件配置。
验证是否达到调优目标，如果达到目标，即可以考虑结束调优；否则，重复完成分析、调整、验证这个过程。


14. java杂谈
Happen-before关系，是Java内存模型中保证多线程操作可见性的机制，也是对早期语言规范中含糊的可见性概念的一个精确定义。
它的具体表现形式，包括但远不止是我们直觉中的synchronized、volatile、lock操作顺序等方面，例如：
线程内执行的每个操作，都保证happen-before后面的操作，这就保证了基本的程序顺序规则，这是开发者在书写程序时的基本约定。
对于volatile变量，对它的写操作，保证happen-before在随后对该变量的读取操作。
对于一个锁的解锁操作，保证happen-before加锁操作。
对象构建完成，保证happen-before于finalizer的开始动作。
甚至是类似线程内部操作的完成，保证happen-before其他Thread.join()的线程等。
这些happen-before关系是存在着传递性的，如果满足a happen-before b和b happen-before c，那么a happen-before c也成立。
前面我一直用happen-before，而不是简单说前后，是因为它不仅仅是对执行时间的保证，也包括对内存读、写操作顺序的保证。仅仅是时钟顺序上的先后，并不能保证线程交互的可见性。


Java的内存模型就是利用了计算机硬件体系，
Java内存模型就是为了解决多线程对共享数据的读写一致性问题












